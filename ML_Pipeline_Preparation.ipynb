{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "This is Machine Learning pipeline preparation, which will be restructed into train_classifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\j8654\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\j8654\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\j8654\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///DisasterResponse.db')\n",
    "df = pd.read_sql(\"SELECT * FROM Response\",engine)\n",
    "X = df[\"message\"]\n",
    "y = df.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization function to process text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize text by using lower case and remove puntuation\n",
    "# tokenize words and lemmatize each word\n",
    "def tokenize(text):\n",
    "    text = re.sub(\"[^a-zA-Z0-9]\",\" \",text)\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    clean_tokens = []\n",
    "    stopwords_list = stopwords.words(\"english\")\n",
    "    for token in tokens:\n",
    "        clean_token = lemmatizer.lemmatize(token).lower().strip()\n",
    "        if (clean_token not in stopwords_list): clean_tokens.append(clean_token)\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a machine learning pipeline\n",
    "Use CountVectorizer to put word count in vectors and Tfidf to statistically measure word frequency and how relevant the word is to the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(LGBMClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.85      0.93      0.89      5001\n",
      "               request       0.79      0.57      0.66      1093\n",
      "                 offer       0.00      0.00      0.00        32\n",
      "           aid_related       0.77      0.68      0.72      2700\n",
      "          medical_help       0.60      0.31      0.41       532\n",
      "      medical_products       0.67      0.29      0.41       345\n",
      "     search_and_rescue       0.64      0.16      0.26       165\n",
      "              security       0.29      0.02      0.03       127\n",
      "              military       0.53      0.31      0.39       197\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.76      0.71      0.73       408\n",
      "                  food       0.82      0.81      0.81       723\n",
      "               shelter       0.74      0.61      0.67       590\n",
      "              clothing       0.67      0.43      0.53        95\n",
      "                 money       0.61      0.30      0.40       138\n",
      "        missing_people       0.67      0.19      0.29        74\n",
      "              refugees       0.64      0.27      0.38       223\n",
      "                 death       0.80      0.53      0.64       301\n",
      "             other_aid       0.58      0.17      0.27       865\n",
      "infrastructure_related       0.40      0.06      0.10       410\n",
      "             transport       0.69      0.21      0.32       288\n",
      "             buildings       0.72      0.37      0.48       331\n",
      "           electricity       0.63      0.25      0.36       144\n",
      "                 tools       0.00      0.00      0.00        46\n",
      "             hospitals       0.43      0.10      0.16        60\n",
      "                 shops       0.00      0.00      0.00        29\n",
      "           aid_centers       0.55      0.08      0.14        77\n",
      "  other_infrastructure       0.26      0.03      0.06       277\n",
      "       weather_related       0.85      0.74      0.79      1816\n",
      "                floods       0.87      0.56      0.69       546\n",
      "                 storm       0.73      0.68      0.70       596\n",
      "                  fire       0.71      0.33      0.45        67\n",
      "            earthquake       0.90      0.82      0.85       630\n",
      "                  cold       0.65      0.34      0.45       122\n",
      "         other_weather       0.54      0.16      0.25       319\n",
      "         direct_report       0.72      0.45      0.55      1265\n",
      "\n",
      "             micro avg       0.79      0.62      0.69     20632\n",
      "             macro avg       0.59      0.35      0.41     20632\n",
      "          weighted avg       0.75      0.62      0.66     20632\n",
      "           samples avg       0.63      0.52      0.53     20632\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j8654\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\j8654\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\j8654\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\j8654\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# y_pred = pd.DataFrame(y_pred,index=X_test.index, columns=y_test.columns)\n",
    "# Though not shown here, LGBM gives better result than simply plugging RandomForest or KNeighbor in pipeline\n",
    "print(classification_report(y_test,y_pred,target_names=y_test.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vect',\n",
       "   CountVectorizer(tokenizer=<function tokenize at 0x000001C74C6B35E0>)),\n",
       "  ('tfidf', TfidfTransformer()),\n",
       "  ('clf', MultiOutputClassifier(estimator=LGBMClassifier()))],\n",
       " 'verbose': False,\n",
       " 'vect': CountVectorizer(tokenizer=<function tokenize at 0x000001C74C6B35E0>),\n",
       " 'tfidf': TfidfTransformer(),\n",
       " 'clf': MultiOutputClassifier(estimator=LGBMClassifier()),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__stop_words': None,\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': <function __main__.tokenize(text)>,\n",
       " 'vect__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'clf__estimator__boosting_type': 'gbdt',\n",
       " 'clf__estimator__class_weight': None,\n",
       " 'clf__estimator__colsample_bytree': 1.0,\n",
       " 'clf__estimator__importance_type': 'split',\n",
       " 'clf__estimator__learning_rate': 0.1,\n",
       " 'clf__estimator__max_depth': -1,\n",
       " 'clf__estimator__min_child_samples': 20,\n",
       " 'clf__estimator__min_child_weight': 0.001,\n",
       " 'clf__estimator__min_split_gain': 0.0,\n",
       " 'clf__estimator__n_estimators': 100,\n",
       " 'clf__estimator__n_jobs': -1,\n",
       " 'clf__estimator__num_leaves': 31,\n",
       " 'clf__estimator__objective': None,\n",
       " 'clf__estimator__random_state': None,\n",
       " 'clf__estimator__reg_alpha': 0.0,\n",
       " 'clf__estimator__reg_lambda': 0.0,\n",
       " 'clf__estimator__silent': True,\n",
       " 'clf__estimator__subsample': 1.0,\n",
       " 'clf__estimator__subsample_for_bin': 200000,\n",
       " 'clf__estimator__subsample_freq': 0,\n",
       " 'clf__estimator': LGBMClassifier(),\n",
       " 'clf__n_jobs': None}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first look at parameters in pipeline for fine-tuning\n",
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('vect',\n",
       "                                        CountVectorizer(tokenizer=<function tokenize at 0x000001C74C6B35E0>)),\n",
       "                                       ('tfidf', TfidfTransformer()),\n",
       "                                       ('clf',\n",
       "                                        MultiOutputClassifier(estimator=LGBMClassifier()))]),\n",
       "             param_grid={'clf__estimator__colsample_bytree': [0.3, 0.7, 1.0],\n",
       "                         'clf__estimator__min_child_samples': [20, 100, 250,\n",
       "                                                               500],\n",
       "                         'vect__max_features': [None, 3000, 6000]},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'clf__estimator__colsample_bytree': [0.3,0.7,1.0],\n",
    "    'clf__estimator__min_child_samples': [20,100,250,500],\n",
    "    'vect__max_features': [None,3000,6000],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters,scoring='f1_micro')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate grid search model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__estimator__colsample_bytree': 0.7,\n",
       " 'clf__estimator__min_child_samples': 20,\n",
       " 'vect__max_features': None}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple grid search gives the same parameters used above, so the evaluation result is also the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.85      0.93      0.89      5001\n",
      "               request       0.79      0.58      0.67      1093\n",
      "                 offer       0.00      0.00      0.00        32\n",
      "           aid_related       0.77      0.68      0.72      2700\n",
      "          medical_help       0.63      0.28      0.39       532\n",
      "      medical_products       0.69      0.30      0.42       345\n",
      "     search_and_rescue       0.62      0.18      0.27       165\n",
      "              security       0.33      0.02      0.04       127\n",
      "              military       0.58      0.32      0.41       197\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.75      0.68      0.71       408\n",
      "                  food       0.83      0.80      0.81       723\n",
      "               shelter       0.76      0.59      0.67       590\n",
      "              clothing       0.67      0.45      0.54        95\n",
      "                 money       0.58      0.30      0.39       138\n",
      "        missing_people       0.74      0.19      0.30        74\n",
      "              refugees       0.67      0.27      0.38       223\n",
      "                 death       0.82      0.54      0.66       301\n",
      "             other_aid       0.60      0.17      0.27       865\n",
      "infrastructure_related       0.44      0.07      0.12       410\n",
      "             transport       0.73      0.21      0.32       288\n",
      "             buildings       0.73      0.37      0.50       331\n",
      "           electricity       0.63      0.22      0.33       144\n",
      "                 tools       0.00      0.00      0.00        46\n",
      "             hospitals       0.35      0.10      0.16        60\n",
      "                 shops       0.00      0.00      0.00        29\n",
      "           aid_centers       0.56      0.06      0.12        77\n",
      "  other_infrastructure       0.29      0.04      0.07       277\n",
      "       weather_related       0.85      0.74      0.79      1816\n",
      "                floods       0.89      0.57      0.69       546\n",
      "                 storm       0.75      0.66      0.70       596\n",
      "                  fire       0.67      0.33      0.44        67\n",
      "            earthquake       0.90      0.81      0.85       630\n",
      "                  cold       0.64      0.31      0.42       122\n",
      "         other_weather       0.58      0.17      0.26       319\n",
      "         direct_report       0.72      0.44      0.55      1265\n",
      "\n",
      "             micro avg       0.80      0.61      0.69     20632\n",
      "             macro avg       0.59      0.34      0.41     20632\n",
      "          weighted avg       0.76      0.61      0.66     20632\n",
      "           samples avg       0.63      0.52      0.53     20632\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j8654\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\j8654\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\j8654\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\j8654\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "final_pred = final_model.predict(X_test)\n",
    "print(classification_report(y_test,final_pred,target_names=y_test.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export model\n",
    "Evaluation of the model from grid search doesn't show significant better performance, so we save original pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_model.sav']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"final_model.sav\"\n",
    "joblib.dump(pipeline, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
